{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ysLXnF7c6R7X"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import random as rn\n",
        "import tensorflow as tfr\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, BatchNormalization\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from skimage import color\n",
        "from sklearn.metrics import classification_report\n",
        "import os\n",
        "import cv2\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "import tensorflow_probability as tfp\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "from tensorflow.keras.layers import MaxPool2D, Dense, ReLU, Softmax, Dropout, Conv2D, Flatten, Conv1D, MaxPool1D, MaxPooling2D, LeakyReLU, Activation\n",
        "from keras.optimizers import Adam\n",
        "from keras import Sequential\n",
        "import seaborn as sn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "Dg6ZrD1f6V2T"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device_list=tf.test.gpu_device_name()\n",
        "print(device_list)\n",
        "if device_list!=\"/device:GPU:0\":\n",
        "    raise SystemError(\"GPU Device not found\")\n",
        "print(\"Found GPU at: {}\".format(device_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKXQeD0D6Z9B",
        "outputId": "4e71dc60-03c9-42f6-8a3e-238b64ae36ff"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/device:GPU:0\n",
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kkn-fv2A6aOK",
        "outputId": "ac57b21b-2556-4086-b3bf-aa25424d8dc0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN_FP:\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        self.seed = 0\n",
        "\n",
        "        self.num_pixels=-1\n",
        "        self.num_classes=-1 #init rand \n",
        "\n",
        "        np.random.seed(self.seed) \n",
        "        rn.seed(self.seed) # Setting the same seed for repeatability\n",
        "        tfr.random.set_seed(self.seed)\n",
        "\n",
        "        self.data_path = '/content/drive/MyDrive/ML_Datasets_Colab_Access/ee456_dataset/inputs/chest_xray/chest_xray/'\n",
        "\n",
        "        self.train_path = self.data_path + 'train/'\n",
        "        self.test_path = self.data_path + 'test/'\n",
        "        self.val_path = self.data_path + 'val/'\n",
        "\n",
        "        self.img_size = 200\n",
        "\n",
        "        self.train_df=[]\n",
        "        self.test_df=[]\n",
        "\n",
        "        self.train=[]\n",
        "        self.test=[]\n",
        "\n",
        "        self.X_train=[]\n",
        "        self.y_train=[]\n",
        "        self.X_test=[]\n",
        "        self.y_test=[]\n",
        "\n",
        "        self.input_shape = None \n",
        "\n",
        "        self.callbacks1=None\n",
        "        self.callbacks2=None\n",
        "        self.callbacks3=None\n",
        "        self.callbacks4=None \n",
        "\n",
        "        self.y_pred=[]\n",
        "        self.y_pre_test=[] #classes to save as compelx np arrays (n-Dim)\n",
        "\n",
        "        self.n_classes=2 #t or f\n",
        "\n",
        "        self.model=None #holder obj\n",
        "\n",
        "        self.classes=['PNEUMONIA', 'NORMAL']\n",
        "\n",
        "        self.num_rand_valids=10\n",
        "        self.batch_size=64\n",
        "        self.max_epochs=50\n",
        "\n",
        "    def read_data(self, data_paths):\n",
        "        \n",
        "        for data_path in data_paths:\n",
        "            \n",
        "            labels = ['PNEUMONIA', 'NORMAL']\n",
        "            images = []\n",
        "            y = []\n",
        "            \n",
        "            for label in labels:\n",
        "                curr_path = data_path + label\n",
        "                for img in os.listdir(curr_path):\n",
        "                    if ('DS' not in img):\n",
        "                        \n",
        "                        image_path = os.path.join(curr_path, img)\n",
        "                        image =  cv2.resize(cv2.imread(image_path), (self.img_size, self.img_size))\n",
        "                        \n",
        "                        if image is not None:\n",
        "                            images.append([image, label])\n",
        "                    \n",
        "        images = np.asarray(images)\n",
        "        \n",
        "        return images\n",
        "\n",
        "    def set_train(self):\n",
        "\n",
        "        self.train = self.read_data([self.train_path])\n",
        "        self.test = self.read_data([self.val_path, self.test_path])\n",
        "\n",
        "        for i in range(10):\n",
        "            \n",
        "            np.random.shuffle(self.train)\n",
        "            np.random.shuffle(self.test)\n",
        "\n",
        "        self.train_df = pd.DataFrame(self.train, columns=['image', 'label'])\n",
        "        self.test_df = pd.DataFrame(self.test, columns = ['image', 'label'])\n",
        "        \n",
        "        pass\n",
        "\n",
        "    def explore_plot(self, type_model): #explore \n",
        "\n",
        "        plt.figure(figsize=(18, 8))\n",
        "        sns.set_style(\"darkgrid\")\n",
        "\n",
        "        plt.subplot(1,2,1)\n",
        "        sns.countplot(self.train_df['label'], palette = 'coolwarm')\n",
        "        plt.title('Train data {}'.format(type_model))\n",
        "\n",
        "        plt.subplot(1,2,2)\n",
        "        sns.countplot(self.test_df['label'], palette = \"hls\")\n",
        "        plt.title('Test data {}'.format(type_model))\n",
        "\n",
        "        plt.savefig(\"/content/drive/MyDrive/ML_Datasets_Colab_Access/EE_456/results/deep/explore_cnn_{}.png\".format(type_model))\n",
        "\n",
        "        pass\n",
        "\n",
        "    def show_example_image(self, type_model):\n",
        "\n",
        "        fig = plt.figure(figsize = (16, 16))\n",
        "        \n",
        "        for idx in range(15):\n",
        "            \n",
        "            plt.subplot(5, 5, idx+1)\n",
        "            plt.imshow(self.train_df.iloc[idx]['image'])\n",
        "            plt.title(\"{} {}\".format(self.train_df.iloc[idx]['label'], type_model))\n",
        "            \n",
        "        plt.tight_layout()\n",
        "\n",
        "        plt.savefig(\"/content/drive/MyDrive/ML_Datasets_Colab_Access/EE_456/results/deep/image_to_label_{}.png\".format(type_model))\n",
        "\n",
        "        pass\n",
        "\n",
        "    def splitdata(self, data):#data prep \n",
        "        \n",
        "        X = []\n",
        "        y = []\n",
        "        \n",
        "        for i, (val, label) in enumerate(data):\n",
        "            \n",
        "            X.append(val)\n",
        "            y.append(self.lung_condition(label))\n",
        "            \n",
        "        return np.array(X), np.array(y)\n",
        "\n",
        "    def preprocesing_to_cnn(self, data):\n",
        "        \n",
        "        data1 = color.rgb2gray(data).reshape(-1, self.img_size, self.img_size, 1).astype('float32')\n",
        "        data1/=255\n",
        "        \n",
        "        return data1\n",
        "\n",
        "    def call_pptocnn(self):\n",
        "\n",
        "        self.X_train = self.preprocesing_to_cnn(self.X_train)\n",
        "        self.X_test = self.preprocesing_to_cnn(self.X_test)\n",
        "\n",
        "        self.num_pixels = self.X_train.shape[1] \n",
        "\n",
        "        self.y_train = to_categorical(self.y_train)\n",
        "        self.y_test = to_categorical(self.y_test)\n",
        "\n",
        "        self.num_classes = self.y_train.shape[1]\n",
        "\n",
        "        self.input_shape = (self.img_size, self.img_size, 1) ##(self.img_size**2, ) ##(self.img_size, self.img_size, 1)\n",
        "\n",
        "        self.num_classes = self.y_train.shape[1]\n",
        "        \n",
        "        pass\n",
        "\n",
        "    def make_callbacks(self):\n",
        "\n",
        "        self.callbacks1 = [EarlyStopping(monitor = 'loss', patience = 6), ReduceLROnPlateau(monitor = 'loss', patience = 3), ModelCheckpoint('models/model.best1.hdf5',monitor='loss', save_best_only=True)]\n",
        "        self.callbacks3 = [ReduceLROnPlateau(monitor = 'loss', patience = 6), ReduceLROnPlateau(monitor = 'loss', patience = 3), ModelCheckpoint('models/model.best3.hdf5', monitor='loss' , save_best_only=True)]\n",
        "        self.callbacks2 = [ReduceLROnPlateau(monitor = 'loss', patience = 6), ReduceLROnPlateau(monitor = 'loss', patience = 3),  ModelCheckpoint('models/model.best2.hdf5', monitor='loss' , save_best_only=True)]\n",
        "        self.callbacks4 = [EarlyStopping(monitor = 'loss', patience = 7), ReduceLROnPlateau(monitor = 'loss', patience = 4), ModelCheckpoint('models/model.best4.hdf5', monitor='loss' , save_best_only=True)]\n",
        "        self.callbacks5 = [EarlyStopping(monitor = 'loss', patience = 7), ReduceLROnPlateau(monitor = 'loss', patience = 4), ModelCheckpoint('models/model.best5.hdf5', monitor='loss' , save_best_only=True)]\n",
        "        \n",
        "        pass\n",
        "\n",
        "    def lung_condition(self, label): #pre-proc\n",
        "        \n",
        "        if label == 'NORMAL':\n",
        "            return 0\n",
        "        \n",
        "        else:\n",
        "            return 1\n",
        "\n",
        "    def set_preproc(self):\n",
        "\n",
        "        np.random.shuffle(self.train)\n",
        "        np.random.shuffle(self.test)\n",
        "        self.X_train, self.y_train = self.splitdata(self.train) #overwrites \n",
        "        self.X_test, self.y_test = self.splitdata(self.test)\n",
        "        \n",
        "        pass\n",
        "\n",
        "    def preprocesing_to_mlp(self, data):\n",
        "        \n",
        "        data1 = color.rgb2gray(data).reshape(-1, self.img_size * self.img_size).astype('float32')\n",
        "        \n",
        "        data1 /= 255 # Data Normalization [0, 1]\n",
        "        \n",
        "        return data1\n",
        "\n",
        "    def mlp_tt(self): \n",
        "\n",
        "        self.X_train = self.preprocesing_to_mlp(self.X_train)\n",
        "        self.X_test = self.preprocesing_to_mlp(self.X_test)\n",
        "\n",
        "        self.num_pixels = self.X_train.shape[1] \n",
        "\n",
        "        self.y_train = to_categorical(self.y_train)\n",
        "        self.y_test = to_categorical(self.y_test)\n",
        "\n",
        "        self.num_classes = self.y_train.shape[1]\n",
        "\n",
        "        self.input_shape = (self.img_size, self.img_size, 1) ##(self.img_size**2, ) ##(self.img_size, self.img_size, 1)\n",
        "\n",
        "        self.num_classes = self.y_train.shape[1]\n",
        "\n",
        "        pass\n",
        "\n",
        "    def draw_learning_curve(self, history, type_model):\n",
        "\n",
        "        epochs_arr=[]\n",
        "\n",
        "        if type_model==\"mlp1\":\n",
        "            epochs_arr=np.arange(0,self.max_epochs)\n",
        "\n",
        "        elif type_model==\"mlp2\":\n",
        "            epochs_arr=np.arange(0,2*self.max_epochs)\n",
        "\n",
        "        elif type_model==\"cnn1\":\n",
        "            epochs_arr=np.arange(0,2*self.max_epochs)\n",
        "\n",
        "        fig = plt.figure(figsize = (16,12))\n",
        "\n",
        "        y_1=np.array(history.history[\"accuracy\"])\n",
        "        y_2=np.array(history.history[\"val_accuracy\"])\n",
        "\n",
        "        plt.plot(epochs_arr, y_1, label=\"train\") \n",
        "        plt.plot(epochs_arr, y_2, label=\"test\")\n",
        "\n",
        "        plt.xlabel(\"Epochs\")\n",
        "        plt.ylabel(\"Accuracy Metric\")\n",
        "\n",
        "        plt.legend(loc='best')\n",
        "        plt.grid(True)\n",
        "\n",
        "        plt.title(\"Accuracy (Train + Test vs. Epochs) {}\".format(type_model))\n",
        "\n",
        "        plt.savefig(\"/content/drive/MyDrive/ML_Datasets_Colab_Access/EE_456/results/deep/\"+\"acc_{}.png\".format(type_model))\n",
        "\n",
        "        fig = plt.figure(figsize = (16,12))\n",
        "\n",
        "        y_1=np.array(history.history[\"loss\"])\n",
        "        y_2=np.array(history.history[\"val_loss\"])\n",
        "\n",
        "        plt.plot(epochs_arr, y_1, label=\"train\") \n",
        "        plt.plot(epochs_arr, y_2, label=\"test\")\n",
        "\n",
        "        plt.xlabel(\"Epochs\")\n",
        "        plt.ylabel(\"Loss Metric\")\n",
        "\n",
        "        plt.legend(loc='best')\n",
        "        plt.grid(True)\n",
        "\n",
        "        plt.title(\"Loss (Train + Test vs. Epochs) {}\".format(type_model))\n",
        "\n",
        "        plt.savefig(\"/content/drive/MyDrive/ML_Datasets_Colab_Access/EE_456/results/deep/\"+\"loss_{}.png\".format(type_model))\n",
        "\n",
        "        pass\n",
        "\n",
        "    def get_mlp(self): #mlp layer, IO premade \n",
        "            \n",
        "        return Sequential([Dense(1024, input_dim = self.num_pixels, activation='relu'), Dense(self.num_classes, activation='softmax')])\n",
        "\n",
        "    def eval_model1(self, type_model):\n",
        "\n",
        "        #self.model = load_model('/content/drive/MyDrive/ML_Datasets_Colab_Access/EE_456/models/model.best1.hdf5')\n",
        "\n",
        "        x_train_now=self.X_train#.flatten() #np.reshape(self.X_train, self.input_shape).flatten()\n",
        "        y_train_now=self.y_train#.flatten() #np.reshape(self.y_train, self.input_shape).flatten()\n",
        "\n",
        "        x_test_now=self.X_test#.flatten()\n",
        "        y_test_now=self.y_test#.flatten()\n",
        "\n",
        "        learning_history = self.model.fit(x_train_now, y_train_now, batch_size = self.batch_size, epochs = self.max_epochs, verbose = 2, callbacks = self.callbacks1, validation_data=(x_test_now, y_test_now))\n",
        "\n",
        "        self.draw_learning_curve(learning_history, type_model)\n",
        "\n",
        "        self.y_pred=self.model.predict(x_test_now)\n",
        "\n",
        "        metric = tf.keras.metrics.TopKCategoricalAccuracy(k=1) \n",
        "        metric.update_state(y_test_now, self.y_pred)\n",
        "        acc=metric.result().numpy()\n",
        "       \n",
        "        print(\"Overall Precision Accuracy for model {}: {}\".format(type_model, acc))\n",
        "\n",
        "        metric_r=tf.keras.metrics.Recall()\n",
        "        metric_r.update_state(y_test_now, self.y_pred)\n",
        "\n",
        "        acc_r=metric_r.result().numpy()\n",
        "\n",
        "        print(\"Overall Recall Accuracy for model {}: {}\".format(type_model, acc_r))\n",
        "\n",
        "        preds=np.argmax(self.y_pred, axis=-1) \n",
        "        labels=np.argmax(y_test_now, axis=1)\n",
        "\n",
        "        print(classification_report(labels,preds, target_names=self.classes))\n",
        "\n",
        "        score = self.model.evaluate(x_test_now, y_test_now, verbose = 0)\n",
        "        print('Test loss for model {}: {}%'.format(type_model, score[0] * 100))\n",
        "        print('Test accuracy for model {}: {}%'.format(type_model, score[1] * 100))\n",
        "\n",
        "        print(\"MLP Error for model {}: {}\".format(type_model, 100 - score[1] * 100))\n",
        "\n",
        "        self.plot_confusion(type_model)\n",
        "        self.random_validations(type_model)\n",
        "\n",
        "        pass\n",
        "\n",
        "    def plot_confusion(self, type_model):\n",
        "\n",
        "        preds=np.argmax(self.y_pred, axis=-1) \n",
        "        labels=np.argmax(self.y_test, axis=-1)\n",
        "\n",
        "        df_cm = confusion_matrix(labels, preds)\n",
        "\n",
        "        t=df_cm[0][0]\n",
        "        df_cm[0][0]=df_cm[0][1]\n",
        "        df_cm[0][1]=t #swap for right conf matr\n",
        "\n",
        "        t=df_cm[1][1]\n",
        "        df_cm[1][1]=df_cm[0][0]\n",
        "        df_cm[0][0]=t #other swap for right class numbers \n",
        "        \n",
        "        plt.figure(figsize = (20,20))\n",
        "\n",
        "        sn.heatmap(df_cm, annot=True, cmap=\"icefire\", linewidths=1, cbar=False, xticklabels=self.classes, yticklabels=self.classes)\n",
        "\n",
        "        plt.xlabel(\"True\")\n",
        "        plt.title(\"Confusion Matrix for Test and Validation: {}\".format(type_model))\n",
        "        plt.ylabel(\"Predicted\")\n",
        "\n",
        "        plt.savefig(\"/content/drive/MyDrive/ML_Datasets_Colab_Access/EE_456/results/deep/\"+\"cm_{}.png\".format(type_model), dpi=100)\n",
        "\n",
        "        pass\n",
        "\n",
        "    def random_validations(self, type_model):\n",
        "        \n",
        "        for i in range(self.num_rand_valids):\n",
        "\n",
        "            p_test = self.model.predict(self.X_test).argmax(axis=1)\n",
        "                            \n",
        "            j = np.random.randint(0, len(self.X_test))\n",
        "\n",
        "            plt.figure(figsize = (12,12))\n",
        "\n",
        "            img_j=np.reshape(self.X_test[j], (self.img_size, self.img_size))\n",
        "\n",
        "            plt.imshow(img_j, cmap='gray')\n",
        "            yv=np.where(self.y_test[j]==1)[0][0]\n",
        "\n",
        "            pvc=np.max(self.y_pred[j])\n",
        "\n",
        "            plt.title(\"True label: {}, Predicted: {} with confidence: {} : {}\".format(self.classes[yv], self.classes[p_test[j]], pvc, type_model))\n",
        "\n",
        "            plt.savefig(\"/content/drive/MyDrive/ML_Datasets_Colab_Access/EE_456/results/deep/pic_{}_{}.png\".format(i, type_model))\n",
        "\n",
        "        pass #not plotted precision and recall per epich, as irrelevant to metric study \n",
        "\n",
        "    def pre_m(self): #model 1\n",
        "\n",
        "        self.model=self.get_mlp()\n",
        "        self.model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "        print(self.model.summary())\n",
        "\n",
        "        pass\n",
        "\n",
        "    def get_mlpv2(self):#model 2\n",
        "            \n",
        "        return Sequential([\n",
        "            Dense(1024, input_dim=self.num_pixels, activation='relu'), \n",
        "            Dropout(0.4), \n",
        "            Dense(512, activation='relu'), \n",
        "            Dropout(0.3), \n",
        "            Dense(128, activation='relu'), \n",
        "            Dropout(0.3), \n",
        "            Dense(self.num_classes, activation='softmax')])\n",
        "\n",
        "    def pre_m2(self):\n",
        "\n",
        "        self.model = self.get_mlpv2()\n",
        "        self.model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "        print(self.model.summary())\n",
        "\n",
        "        pass\n",
        "\n",
        "    def eval_model2(self, type_model):\n",
        "\n",
        "        #self.model = load_model('/content/drive/MyDrive/ML_Datasets_Colab_Access/EE_456/models/model.best2.hdf5')\n",
        "\n",
        "        x_train_now=self.X_train#.flatten() #np.reshape(self.X_train, self.input_shape).flatten()\n",
        "        y_train_now=self.y_train#.flatten() #np.reshape(self.y_train, self.input_shape).flatten()\n",
        "\n",
        "        x_test_now=self.X_test#.flatten()\n",
        "        y_test_now=self.y_test#.flatten()\n",
        "\n",
        "        learning_history = self.model.fit(x_train_now, y_train_now, batch_size = self.batch_size, epochs = self.max_epochs*2, verbose = 2, callbacks = self.callbacks2, validation_data=(x_test_now, y_test_now))\n",
        "\n",
        "        score = self.model.evaluate(self.X_test, self.y_test, verbose = 0)\n",
        "        print('Test loss for model {}: {}%'.format(type_model, score[0] * 100))\n",
        "        print('Test accuracy for model {}: {}%'.format(type_model, score[1] * 100))\n",
        "\n",
        "        print(\"MLP Error for model {}: {}\".format(type_model, 100 - score[1] * 100))\n",
        "\n",
        "        self.draw_learning_curve(learning_history, type_model)\n",
        "\n",
        "        self.y_pred=self.model.predict(x_test_now)\n",
        "\n",
        "        metric = tf.keras.metrics.TopKCategoricalAccuracy(k=1) \n",
        "        metric.update_state(y_test_now, self.y_pred)\n",
        "        acc=metric.result().numpy()\n",
        "       \n",
        "        print(\"Overall Precision Accuracy for model {}: {}\".format(type_model, acc))\n",
        "\n",
        "        metric_r=tf.keras.metrics.Recall()\n",
        "        metric_r.update_state(y_test_now, self.y_pred)\n",
        "\n",
        "        acc_r=metric_r.result().numpy()\n",
        "\n",
        "        print(\"Overall Recall Accuracy for model {}: {}\".format(type_model, acc_r))\n",
        "\n",
        "        preds=np.argmax(self.y_pred, axis=-1) \n",
        "        labels=np.argmax(y_test_now, axis=1)\n",
        "\n",
        "        print(classification_report(labels,preds, target_names=self.classes))\n",
        "\n",
        "        self.plot_confusion(type_model)\n",
        "        self.random_validations(type_model)\n",
        "\n",
        "        pass\n",
        "\n",
        "    def data_aug(self): #data aug\n",
        "\n",
        "        datagen = ImageDataGenerator(featurewise_center = False, samplewise_center = False, featurewise_std_normalization = False, samplewise_std_normalization = False, zca_whitening = False, horizontal_flip = False, vertical_flip = False, rotation_range = 10, zoom_range = 0.1, width_shift_range = 0.1, height_shift_range = 0.1)\n",
        "\n",
        "        datagen.fit(self.X_train)\n",
        "        self.train_gen = datagen.flow(self.X_train, self.y_train, batch_size = 32)\n",
        "\n",
        "        #pass\n",
        "        return self.train_gen\n",
        "        \n",
        "    def get_modelvgg(self): #VGG model\n",
        "        return Sequential([Conv2D(input_shape= self.input_shape ,filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"),\n",
        "                           Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"),\n",
        "                           MaxPool2D(pool_size=(2,2),strides=(2,2)),\n",
        "                           Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
        "                           Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
        "                           MaxPool2D(pool_size=(2,2),strides=(2,2)),\n",
        "                           Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
        "                           Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
        "                           Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
        "                           MaxPool2D(pool_size=(2,2),strides=(2,2)),\n",
        "                           Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
        "                           Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
        "                           Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
        "                           MaxPool2D(pool_size=(2,2),strides=(2,2)),\n",
        "                           Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
        "                           Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
        "                           Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
        "                           MaxPool2D(pool_size=(2,2),strides=(2,2)),\n",
        "                           Flatten(),\n",
        "                           Dense(units=4096,activation=\"relu\"),\n",
        "                           Dense(units=4096,activation=\"relu\"),\n",
        "                           Dense(self.num_classes, activation=\"softmax\")])\n",
        "    \n",
        "    def eval_vgg(self, type_model):\n",
        "\n",
        "        self.model = self.get_modelvgg()\n",
        "        self.model.compile(loss = 'categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
        "        #self.model.summary()\n",
        "\n",
        "        x_train_now=self.X_train\n",
        "        y_train_now=self.y_train\n",
        "\n",
        "        x_test_now=self.X_test\n",
        "        y_test_now=self.y_test\n",
        "\n",
        "        train_gen = self.data_aug()\n",
        "        #learning_history = self.model.fit(x_train_now, y_train_now, batch_size = 32, epochs = 50, verbose = 1, callbacks = self.callbacks5, validation_data = (x_test_now, y_test_now))\n",
        "        learning_history = self.model.fit_generator((train_gen), epochs = 50, steps_per_epoch = self.X_train.shape[0] // 32, validation_data = (self.X_test, self.y_test), callbacks = self.callbacks5)\n",
        "\n",
        "        score = self.model.evaluate(self.X_test, self.y_test, verbose = 0)\n",
        "        print('Test loss: {}%'.format(score[0] * 100))\n",
        "        print('Test accuracy: {}%'.format(score[1] * 100))\n",
        "\n",
        "        print(\"MLP Error: %.2f%%\" % (100 - score[1] * 100))\n",
        "\n",
        "        self.draw_learning_curve(learning_history, type_model)\n",
        "\n",
        "        y_pred = self.model.predict(self.X_test) #pred 2\n",
        "        self.y_pred = np.argmax(y_pred, axis = 1)\n",
        "\n",
        "        self.y_pre_test = np.argmax(self.y_test, axis = 1)\n",
        "\n",
        "        pass\n",
        "        #score = self.model.evaluate(self.X_test, self.y_test, verbose = 0)\n",
        "        #print('Test loss for model {}: {}%'.format(type_model, score[0]))\n",
        "        #print('Test accuracy for model {}: {}%'.format(type_model, score[1] * 100))\n",
        "\n",
        "        #print(\"MLP Error for model {}: {}\".format(type_model, 100 - score[1] * 100))\n",
        "\n",
        "        #self.draw_learning_curve(learning_history, type_model)\n",
        "\n",
        "        #self.y_pred=self.model.predict(x_test_now)\n",
        "\n",
        "        #metric = tf.keras.metrics.TopKCategoricalAccuracy(k=1) \n",
        "        #metric.update_state(y_test_now, self.y_pred)\n",
        "        #acc=metric.result().numpy()\n",
        "       \n",
        "        #print(\"Overall Precision Accuracy for model {}: {}\".format(type_model, acc))\n",
        "\n",
        "        #metric_r=tf.keras.metrics.Recall()\n",
        "        #metric_r.update_state(y_test_now, self.y_pred)\n",
        "\n",
        "        #acc_r=metric_r.result().numpy()\n",
        "\n",
        "        #print(\"Overall Recall Accuracy for model {}: {}\".format(type_model, acc_r))\n",
        "\n",
        "        #preds=np.argmax(self.y_pred, axis=-1) \n",
        "        #labels=np.argmax(y_test_now, axis=1)\n",
        "\n",
        "        #print(classification_report(labels,preds, target_names=self.classes))\n",
        "\n",
        "        #self.plot_confusion(type_model)\n",
        "        #self.random_validations(type_model)\n",
        "\n",
        "        #pass\n",
        "\n",
        "    def get_modelcnn(self): #CNN model\n",
        "\n",
        "        return Sequential([Conv2D(16, kernel_size=(3, 3), activation='relu', padding='same', input_shape = self.input_shape), \n",
        "                           Conv2D(16, kernel_size=(3, 3), activation='relu', padding='same'), \n",
        "                           BatchNormalization(), \n",
        "                           MaxPool2D(pool_size=(2, 2)), \n",
        "                           Dropout(0.25), \n",
        "                           Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'), \n",
        "                           Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'), \n",
        "                           BatchNormalization(), \n",
        "                           MaxPool2D(pool_size=(2, 2)), \n",
        "                           Dropout(0.25), \n",
        "                           Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'), \n",
        "                           Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'), \n",
        "                           BatchNormalization(), \n",
        "                           MaxPool2D(pool_size=(2, 2)), \n",
        "                           Dropout(0.25), \n",
        "                           Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same' ), \n",
        "                           Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'), \n",
        "                           BatchNormalization(), \n",
        "                           MaxPool2D(pool_size=(2, 2)), \n",
        "                           Dropout(0.25), \n",
        "                           Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same' ), \n",
        "                           Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'), \n",
        "                           BatchNormalization(), \n",
        "                           MaxPool2D(pool_size=(2, 2)), \n",
        "                           Dropout(0.25), \n",
        "                           Flatten(), \n",
        "                           Dense(512, activation='relu'), \n",
        "                           Dropout(0.5), \n",
        "                           Dense(256, activation='relu'), \n",
        "                           Dropout(0.5), \n",
        "                           Dense(64, activation='relu'), \n",
        "                           Dropout(0.5), \n",
        "                           Dense(self.num_classes, activation = \"softmax\")])\n",
        "\n",
        "    def eval_cnn_m1(self, type_model): #fit and eval cnn 1\n",
        "\n",
        "        self.model = self.get_modelcnn()\n",
        "        self.model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
        "\n",
        "        x_train_now=self.X_train#.flatten() #np.reshape(self.X_train, self.input_shape).flatten()\n",
        "        y_train_now=self.y_train#.flatten() #np.reshape(self.y_train, self.input_shape).flatten()\n",
        "\n",
        "        x_test_now=self.X_test#.flatten()\n",
        "        y_test_now=self.y_test#.flatten()\n",
        "\n",
        "        learning_history = self.model.fit(x_train_now, y_train_now, batch_size = 64, epochs = 100, verbose = 1, callbacks = self.callbacks3, validation_data = (x_test_now, y_test_now))\n",
        "\n",
        "        #self.model = load_model('/content/drive/MyDrive/ML_Datasets_Colab_Access/EE_456/models/model.best3.hdf5')\n",
        "\n",
        "        score = self.model.evaluate(self.X_test, self.y_test, verbose = 0)\n",
        "        print('Test loss for model {}: {}%'.format(type_model, score[0]))\n",
        "        print('Test accuracy for model {}: {}%'.format(type_model, score[1] * 100))\n",
        "\n",
        "        print(\"MLP Error for model {}: {}\".format(type_model, 100 - score[1] * 100))\n",
        "\n",
        "        self.draw_learning_curve(learning_history, type_model)\n",
        "\n",
        "        self.y_pred=self.model.predict(x_test_now)\n",
        "\n",
        "        metric = tf.keras.metrics.TopKCategoricalAccuracy(k=1) \n",
        "        metric.update_state(y_test_now, self.y_pred)\n",
        "        acc=metric.result().numpy()\n",
        "       \n",
        "        print(\"Overall Precision Accuracy for model {}: {}\".format(type_model, acc))\n",
        "\n",
        "        metric_r=tf.keras.metrics.Recall()\n",
        "        metric_r.update_state(y_test_now, self.y_pred)\n",
        "\n",
        "        acc_r=metric_r.result().numpy()\n",
        "\n",
        "        print(\"Overall Recall Accuracy for model {}: {}\".format(type_model, acc_r))\n",
        "\n",
        "        preds=np.argmax(self.y_pred, axis=-1) \n",
        "        labels=np.argmax(y_test_now, axis=1)\n",
        "\n",
        "        print(classification_report(labels,preds, target_names=self.classes))\n",
        "\n",
        "        self.plot_confusion(type_model)\n",
        "        self.random_validations(type_model)\n",
        "\n",
        "        pass\n",
        "\n",
        "    def get_modelcnn_v2(self): #cnn model 2:\n",
        "\n",
        "        return Sequential([\n",
        "            Conv2D(16, kernel_size=(3, 3), activation='relu', padding='same', input_shape = self.input_shape), \n",
        "            Conv2D(16, kernel_size=(3, 3), activation='relu', padding='same'), \n",
        "            BatchNormalization(), \n",
        "            MaxPool2D(pool_size=(2, 2)), \n",
        "            Dropout(0.2), \n",
        "            Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'), \n",
        "            Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'), \n",
        "            BatchNormalization(), \n",
        "            MaxPool2D(pool_size=(2, 2)),\n",
        "            Dropout(0.2), \n",
        "            Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'), \n",
        "            Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'), \n",
        "            BatchNormalization(), \n",
        "            MaxPool2D(pool_size=(2, 2)), \n",
        "            Dropout(0.2), \n",
        "            Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
        "            Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'), \n",
        "            BatchNormalization(), \n",
        "            MaxPool2D(pool_size=(2, 2)), \n",
        "            Dropout(0.2), \n",
        "            Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'), \n",
        "            Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'), \n",
        "            BatchNormalization(), \n",
        "            MaxPool2D(pool_size=(2, 2)), \n",
        "            Dropout(0.2), \n",
        "            Flatten(), \n",
        "            Dense(1024, activation='relu'), \n",
        "            BatchNormalization(), \n",
        "            Dropout(0.5), \n",
        "            Dense(512, activation='relu'), \n",
        "            BatchNormalization(), \n",
        "            Dropout(0.4), \n",
        "            Dense(256, activation='relu'), \n",
        "            BatchNormalization(), \n",
        "            Dropout(0.3), \n",
        "            Dense(64, activation='relu'), \n",
        "            BatchNormalization(), \n",
        "            Dropout(0.2), \n",
        "            Dense(self.num_classes, activation = \"softmax\")])\n",
        "\n",
        "    def eval_cnn_model2(self, type_model):\n",
        "\n",
        "        self.model = self.get_modelcnn_v2()\n",
        "        self.model.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
        "        self.model.summary()\n",
        "\n",
        "        learning_history = self.model.fit_generator((self.train_gen), epochs = 100, steps_per_epoch = self.X_train.shape[0] // 32, validation_data = (self.X_test, self.y_test), callbacks = self.callbacks4)\n",
        "\n",
        "        #self.model = load_model('/content/drive/MyDrive/ML_Datasets_Colab_Access/EE_456/models/model.best4.hdf5')\n",
        "\n",
        "        score = self.model.evaluate(self.X_test, self.y_test, verbose = 0)\n",
        "        print('Test loss: {}%'.format(score[0] * 100))\n",
        "        print('Test accuracy: {}%'.format(score[1] * 100))\n",
        "\n",
        "        print(\"MLP Error: %.2f%%\" % (100 - score[1] * 100))\n",
        "\n",
        "        self.draw_learning_curve(learning_history, type_model)\n",
        "\n",
        "        y_pred = self.model.predict(self.X_test) #pred 2\n",
        "        self.y_pred = np.argmax(y_pred, axis = 1)\n",
        "\n",
        "        self.y_pre_test = np.argmax(self.y_test, axis = 1)\n",
        "\n",
        "        pass\n",
        "\n",
        "    def show_condition(self, num):\n",
        "        \n",
        "        if num == 0:\n",
        "            return 'NORMAL'\n",
        "        \n",
        "        return 'PNEUMONIA'\n",
        "\n",
        "    def final_classification(self, type_model):\n",
        "\n",
        "        cnt_error = []\n",
        "        for idx, (a, b) in enumerate(zip(self.y_pre_test, self.y_pred)):\n",
        "            if a == b: \n",
        "                continue\n",
        "            cnt_error.append(a)# test\n",
        "\n",
        "        cnt_error = np.unique(cnt_error, return_counts = True)\n",
        "        sns.set_style(\"darkgrid\")\n",
        "        plt.figure(figsize = (15, 7))\n",
        "        sns.barplot([self.show_condition(x) for x in cnt_error[0]], cnt_error[1], palette=\"muted\")\n",
        "        \n",
        "        plt.savefig(\"results/deep/final_class_{}.png\".format(type_model))\n",
        "\n",
        "        cnt_ind = 1\n",
        "        list_idx = []\n",
        "        fig = plt.figure(figsize=(14, 14))\n",
        "        X_test_plot = self.X_test.reshape(-1, self.img_size, self.img_size)\n",
        "        \n",
        "        for idx, (a, b) in enumerate(zip(self.y_pre_test, self.y_pred)):\n",
        "            \n",
        "            if(cnt_ind > 16):\n",
        "                break\n",
        "            \n",
        "            if a == b: \n",
        "                continue\n",
        "            \n",
        "            plt.subplot(4, 4, cnt_ind)\n",
        "            plt.imshow(X_test_plot[idx], cmap='gray', interpolation='none')\n",
        "            plt.title('y_true = {0}\\ny_pred = {1}\\n ind = {2}'.format(self.show_condition(a), self.show_condition(b), idx))\n",
        "            plt.tight_layout()\n",
        "            list_idx.append(idx)\n",
        "            cnt_ind += 1\n",
        "\n",
        "            \n",
        "\n",
        "        print(classification_report(self.y_pre_test, self.y_pred)) #report class\n",
        "\n",
        "        pass\n",
        "\n",
        "    def run_sequence_model1(self): #model 1 normal mlp\n",
        "\n",
        "        type_model=\"mlp1\"\n",
        "        \n",
        "        print(\"\\nRunning MLP Model #1 ... \\n\")\n",
        "\n",
        "        self.set_train()\n",
        "        self.explore_plot(type_model)\n",
        "        self.show_example_image(type_model)\n",
        "        self.set_preproc()\n",
        "        self.mlp_tt()\n",
        "        \n",
        "        self.make_callbacks()\n",
        "        self.pre_m()\n",
        "        self.eval_model1(type_model)\n",
        "        \n",
        "        print(\"\\nMLP Model 1 Generated. \\n\")\n",
        "\n",
        "        pass\n",
        "\n",
        "    def run_sequence_model2(self): #model 2 normal mlp\n",
        "\n",
        "        type_model=\"mlp2\"\n",
        "        \n",
        "        print(\"\\nRunning MLP Model #2 ... \\n\")\n",
        "    \n",
        "        self.set_train()\n",
        "        self.explore_plot(type_model)\n",
        "        self.show_example_image(type_model)\n",
        "        self.set_preproc()\n",
        "        self.mlp_tt()\n",
        "        \n",
        "        self.make_callbacks()\n",
        "        self.pre_m2()\n",
        "        self.eval_model2(type_model)\n",
        "        \n",
        "        print(\"\\nMLP Model 2 Generated. \\n\")\n",
        "\n",
        "        pass\n",
        "\n",
        "    def run_sequence_model3(self): #cnn layers v1\n",
        "\n",
        "        type_model=\"cnn1\"\n",
        "        \n",
        "        print(\"\\nRunning CNN Model #1 ... \\n\")\n",
        "\n",
        "        self.set_train()\n",
        "        self.explore_plot(type_model)\n",
        "        self.show_example_image(type_model) #added from MLPs\n",
        "\n",
        "        self.set_preproc()\n",
        "        self.call_pptocnn()\n",
        "\n",
        "        self.make_callbacks()\n",
        "        self.get_modelcnn()\n",
        "        self.eval_cnn_m1(type_model)\n",
        "        \n",
        "        print(\"\\nCNN Model 1 Generated. \\n\")\n",
        "\n",
        "        pass\n",
        "\n",
        "    def run_sequence_model4(self): #cnn model v2\n",
        "\n",
        "        type_model=\"cnn2\"\n",
        "        \n",
        "        print(\"\\nRunning CNN Model #2 ... \\n\")\n",
        "    \n",
        "        self.data_aug()\n",
        "        self.make_callbacks()\n",
        "\n",
        "        self.get_modelcnn_v2()\n",
        "        self.eval_cnn_model2(type_model)\n",
        "        self.final_classification()\n",
        "        \n",
        "        print(\"\\nCNN Model 2 Generated. \\n\")\n",
        "        \n",
        "        pass\n",
        "\n",
        "    def run_sequence_model5(self): #vgg16\n",
        "\n",
        "        type_model=\"cnn1\"\n",
        "        \n",
        "        print(\"\\nRunning CNN Model #3 ... \\n\")\n",
        "\n",
        "        self.set_train()\n",
        "        #self.explore_plot(type_model)\n",
        "        #self.show_example_image(type_model) #added from MLPs\n",
        "\n",
        "        self.set_preproc()\n",
        "        self.call_pptocnn()\n",
        "\n",
        "        self.make_callbacks()\n",
        "        self.get_modelvgg()\n",
        "        self.eval_vgg(type_model)\n",
        "        \n",
        "        print(\"\\nCNN Model 3 Generated. \\n\")\n",
        "\n",
        "        pass"
      ],
      "metadata": {
        "id": "Qwdn8tPy6aRH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#start\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "\n",
        "    cfp=CNN_FP()\n",
        "    #cfp.run_sequence_model1()\n",
        "    #cfp.run_sequence_model2()\n",
        "    #cfp.run_sequence_model3() #only 1 deep CNN\n",
        "    #cfp.run_sequence_model4()\n",
        "    cfp.run_sequence_model5()\n",
        "\n",
        "#end\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gRKrsTc36hme",
        "outputId": "cd0a32aa-7c0c-42c1-d77a-49f20a5637a0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running CNN Model #3 ... \n",
            "\n",
            "Epoch 1/50\n",
            "162/162 [==============================] - 88s 448ms/step - loss: 0.5850 - accuracy: 0.7390 - val_loss: 0.6683 - val_accuracy: 0.6250 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "162/162 [==============================] - 66s 406ms/step - loss: 0.5743 - accuracy: 0.7421 - val_loss: 0.6804 - val_accuracy: 0.6250 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "162/162 [==============================] - 66s 406ms/step - loss: 0.5733 - accuracy: 0.7427 - val_loss: 0.6841 - val_accuracy: 0.6250 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "162/162 [==============================] - 66s 404ms/step - loss: 0.5717 - accuracy: 0.7427 - val_loss: 0.6702 - val_accuracy: 0.6250 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "162/162 [==============================] - 60s 370ms/step - loss: 0.5725 - accuracy: 0.7425 - val_loss: 0.6874 - val_accuracy: 0.6250 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "162/162 [==============================] - 65s 404ms/step - loss: 0.5716 - accuracy: 0.7429 - val_loss: 0.6918 - val_accuracy: 0.6250 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "162/162 [==============================] - 66s 405ms/step - loss: 0.5707 - accuracy: 0.7429 - val_loss: 0.7013 - val_accuracy: 0.6250 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "162/162 [==============================] - 60s 370ms/step - loss: 0.5720 - accuracy: 0.7423 - val_loss: 0.6738 - val_accuracy: 0.6250 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "162/162 [==============================] - 60s 370ms/step - loss: 0.5719 - accuracy: 0.7429 - val_loss: 0.6842 - val_accuracy: 0.6250 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "162/162 [==============================] - 60s 370ms/step - loss: 0.5718 - accuracy: 0.7421 - val_loss: 0.7028 - val_accuracy: 0.6250 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "162/162 [==============================] - 60s 370ms/step - loss: 0.5709 - accuracy: 0.7437 - val_loss: 0.6800 - val_accuracy: 0.6250 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "162/162 [==============================] - 60s 369ms/step - loss: 0.5717 - accuracy: 0.7421 - val_loss: 0.6903 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 13/50\n",
            "162/162 [==============================] - 66s 405ms/step - loss: 0.5697 - accuracy: 0.7433 - val_loss: 0.6978 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 14/50\n",
            "162/162 [==============================] - 60s 370ms/step - loss: 0.5706 - accuracy: 0.7425 - val_loss: 0.6978 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 15/50\n",
            "162/162 [==============================] - 60s 370ms/step - loss: 0.5711 - accuracy: 0.7419 - val_loss: 0.7031 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 16/50\n",
            "162/162 [==============================] - 65s 404ms/step - loss: 0.5695 - accuracy: 0.7437 - val_loss: 0.6996 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 17/50\n",
            "162/162 [==============================] - 60s 371ms/step - loss: 0.5705 - accuracy: 0.7425 - val_loss: 0.6921 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 18/50\n",
            "162/162 [==============================] - 60s 370ms/step - loss: 0.5699 - accuracy: 0.7431 - val_loss: 0.6941 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 19/50\n",
            "162/162 [==============================] - 60s 371ms/step - loss: 0.5705 - accuracy: 0.7425 - val_loss: 0.6895 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 20/50\n",
            "162/162 [==============================] - 60s 370ms/step - loss: 0.5710 - accuracy: 0.7421 - val_loss: 0.6950 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 21/50\n",
            "162/162 [==============================] - 60s 371ms/step - loss: 0.5708 - accuracy: 0.7421 - val_loss: 0.6947 - val_accuracy: 0.6250 - lr: 1.0000e-05\n",
            "Epoch 22/50\n",
            "162/162 [==============================] - 66s 405ms/step - loss: 0.5694 - accuracy: 0.7435 - val_loss: 0.6947 - val_accuracy: 0.6250 - lr: 1.0000e-05\n",
            "Epoch 23/50\n",
            "162/162 [==============================] - 60s 371ms/step - loss: 0.5700 - accuracy: 0.7429 - val_loss: 0.6950 - val_accuracy: 0.6250 - lr: 1.0000e-05\n",
            "Epoch 24/50\n",
            "162/162 [==============================] - 60s 371ms/step - loss: 0.5702 - accuracy: 0.7427 - val_loss: 0.6948 - val_accuracy: 0.6250 - lr: 1.0000e-05\n",
            "Epoch 25/50\n",
            "162/162 [==============================] - 60s 369ms/step - loss: 0.5696 - accuracy: 0.7433 - val_loss: 0.6948 - val_accuracy: 0.6250 - lr: 1.0000e-06\n",
            "Epoch 26/50\n",
            "162/162 [==============================] - 60s 370ms/step - loss: 0.5698 - accuracy: 0.7431 - val_loss: 0.6948 - val_accuracy: 0.6250 - lr: 1.0000e-06\n",
            "Epoch 27/50\n",
            "162/162 [==============================] - 60s 371ms/step - loss: 0.5700 - accuracy: 0.7429 - val_loss: 0.6949 - val_accuracy: 0.6250 - lr: 1.0000e-06\n",
            "Epoch 28/50\n",
            "162/162 [==============================] - 60s 370ms/step - loss: 0.5708 - accuracy: 0.7421 - val_loss: 0.6948 - val_accuracy: 0.6250 - lr: 1.0000e-06\n",
            "Epoch 29/50\n",
            "162/162 [==============================] - 60s 370ms/step - loss: 0.5696 - accuracy: 0.7433 - val_loss: 0.6948 - val_accuracy: 0.6250 - lr: 1.0000e-07\n",
            "Test loss: 69.4818913936615%\n",
            "Test accuracy: 62.5%\n",
            "MLP Error: 37.50%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-e819bd05fcf1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#cfp.run_sequence_model3() #only 1 deep CNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#cfp.run_sequence_model4()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mcfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_sequence_model5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-763868890352>\u001b[0m in \u001b[0;36mrun_sequence_model5\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    824\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_modelvgg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 826\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_vgg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nCNN Model 3 Generated. \\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-763868890352>\u001b[0m in \u001b[0;36meval_vgg\u001b[0;34m(self, type_model)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MLP Error: %.2f%%\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_learning_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#pred 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-763868890352>\u001b[0m in \u001b[0;36mdraw_learning_curve\u001b[0;34m(self, history, type_model)\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0my_2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2759\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mdocstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2760\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2761\u001b[0;31m     return gca().plot(\n\u001b[0m\u001b[1;32m   2762\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[1;32m   2763\u001b[0m         is not None else {}), **kwargs)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1645\u001b[0m         \"\"\"\n\u001b[1;32m   1646\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1647\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1648\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    343\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (100,) and (29,)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x864 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}