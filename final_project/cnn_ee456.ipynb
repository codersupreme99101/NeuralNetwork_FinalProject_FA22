{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyOQCr617i/IBCGt1ec6aZ+x"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"premium"},"cells":[{"cell_type":"markdown","source":["Get the Libraries"],"metadata":{"id":"WHjIaeyTLVM7"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"LUzL3lrEKvab","executionInfo":{"status":"ok","timestamp":1668905913705,"user_tz":300,"elapsed":4555,"user":{"displayName":"Arya Keni","userId":"06459928781733841639"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd \n","import random as rn\n","import tensorflow as tfr\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.layers import Dense, Dropout, Flatten\n","from tensorflow.keras.layers import Conv2D, MaxPool2D, BatchNormalization\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from skimage import color\n","from sklearn.metrics import classification_report\n","import os\n","import cv2\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import classification_report\n","import tensorflow_probability as tfp\n","\n","import tensorflow as tf\n","from keras.utils import to_categorical\n","\n","from tensorflow.keras.layers import MaxPool2D, Dense, ReLU, Softmax, Dropout, Conv2D, Flatten, Conv1D, MaxPool1D, MaxPooling2D, LeakyReLU, Activation\n","from keras.optimizers import Adam\n","from keras import Sequential\n","import seaborn as sn"]},{"cell_type":"markdown","source":["GPU Connection - for Extended ML"],"metadata":{"id":"M2QK3y2dt5rN"}},{"cell_type":"code","source":["import tensorflow as tf\n","import warnings\n","warnings.filterwarnings(\"ignore\")"],"metadata":{"id":"NQW2AVB5ugku","executionInfo":{"status":"ok","timestamp":1668905942890,"user_tz":300,"elapsed":184,"user":{"displayName":"Arya Keni","userId":"06459928781733841639"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["device_list=tf.test.gpu_device_name()\n","print(device_list)\n","if device_list!=\"/device:GPU:0\":\n","    raise SystemError(\"GPU Device not found\")\n","print(\"Found GPU at: {}\".format(device_list))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wvdFjdsAt7tK","executionInfo":{"status":"ok","timestamp":1668905970505,"user_tz":300,"elapsed":173,"user":{"displayName":"Arya Keni","userId":"06459928781733841639"}},"outputId":"b193d075-a627-4615-90b5-b3cf5e2c1a0a"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/device:GPU:0\n","Found GPU at: /device:GPU:0\n"]}]},{"cell_type":"markdown","source":["Device Mount"],"metadata":{"id":"orlBz7BAuA32"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/', force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pcih947nuB13","executionInfo":{"status":"ok","timestamp":1668905985940,"user_tz":300,"elapsed":15438,"user":{"displayName":"Arya Keni","userId":"06459928781733841639"}},"outputId":"69ab6777-332f-4b48-a34e-fd7652a4c3bc"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"markdown","source":["Class for 4 models"],"metadata":{"id":"K0bbnmGELX6o"}},{"cell_type":"code","source":["class CNN_FP:\n","\n","    def __init__(self):\n","\n","        self.seed = 0\n","\n","        self.num_pixels=-1\n","        self.num_classes=-1 #init rand \n","\n","        np.random.seed(self.seed) \n","        rn.seed(self.seed) # Setting the same seed for repeatability\n","        tfr.random.set_seed(self.seed)\n","\n","        self.data_path = '/content/drive/MyDrive/ML_Datasets_Colab_Access/ee456_dataset/inputs/chest_xray/chest_xray/'\n","\n","        self.train_path = self.data_path + 'train/'\n","        self.test_path = self.data_path + 'test/'\n","        self.val_path = self.data_path + 'val/'\n","\n","        self.img_size = 200\n","\n","        self.train_df=[]\n","        self.test_df=[]\n","\n","        self.train=[]\n","        self.test=[]\n","\n","        self.X_train=[]\n","        self.y_train=[]\n","        self.X_test=[]\n","        self.y_test=[]\n","\n","        self.input_shape = None \n","\n","        self.callbacks1=None\n","        self.callbacks2=None\n","        self.callbacks3=None\n","        self.callbacks4=None \n","\n","        self.y_pred=[]\n","        self.y_pre_test=[] #classes to save as compelx np arrays (n-Dim)\n","\n","        self.n_classes=2 #t or f\n","\n","        self.model=None #holder obj\n","\n","        self.classes=['PNEUMONIA', 'NORMAL']\n","\n","        self.num_rand_valids=10\n","        self.batch_size=64\n","        self.max_epochs=50\n","\n","    def read_data(self, data_paths):\n","        \n","        for data_path in data_paths:\n","            \n","            labels = ['PNEUMONIA', 'NORMAL']\n","            images = []\n","            y = []\n","            \n","            for label in labels:\n","                curr_path = data_path + label\n","                for img in os.listdir(curr_path):\n","                    if ('DS' not in img):\n","                        \n","                        image_path = os.path.join(curr_path, img)\n","                        image =  cv2.resize(cv2.imread(image_path), (self.img_size, self.img_size))\n","                        \n","                        if image is not None:\n","                            images.append([image, label])\n","                    \n","        images = np.asarray(images)\n","        \n","        return images\n","\n","    def set_train(self):\n","\n","        self.train = self.read_data([self.train_path])\n","        self.test = self.read_data([self.val_path, self.test_path])\n","\n","        for i in range(10):\n","            \n","            np.random.shuffle(self.train)\n","            np.random.shuffle(self.test)\n","\n","        self.train_df = pd.DataFrame(self.train, columns=['image', 'label'])\n","        self.test_df = pd.DataFrame(self.test, columns = ['image', 'label'])\n","        \n","        pass\n","\n","    def explore_plot(self, type_model): #explore \n","\n","        plt.figure(figsize=(18, 8))\n","        sns.set_style(\"darkgrid\")\n","\n","        plt.subplot(1,2,1)\n","        sns.countplot(self.train_df['label'], palette = 'coolwarm')\n","        plt.title('Train data {}'.format(type_model))\n","\n","        plt.subplot(1,2,2)\n","        sns.countplot(self.test_df['label'], palette = \"hls\")\n","        plt.title('Test data {}'.format(type_model))\n","\n","        plt.savefig(\"/content/drive/MyDrive/ML_Datasets_Colab_Access/EE_456/results/explore_cnn_{}.png\".format(type_model))\n","\n","        pass\n","\n","    def show_example_image(self, type_model):\n","\n","        fig = plt.figure(figsize = (16, 16))\n","        \n","        for idx in range(15):\n","            \n","            plt.subplot(5, 5, idx+1)\n","            plt.imshow(self.train_df.iloc[idx]['image'])\n","            plt.title(\"{} {}\".format(self.train_df.iloc[idx]['label'], type_model))\n","            \n","        plt.tight_layout()\n","\n","        plt.savefig(\"/content/drive/MyDrive/ML_Datasets_Colab_Access/EE_456/results/image_to_label_{}.png\".format(type_model))\n","\n","        pass\n","\n","    def splitdata(self, data):#data prep \n","        \n","        X = []\n","        y = []\n","        \n","        for i, (val, label) in enumerate(data):\n","            \n","            X.append(val)\n","            y.append(self.lung_condition(label))\n","            \n","        return np.array(X), np.array(y)\n","\n","    def preprocesing_to_cnn(self, data):\n","        \n","        data1 = color.rgb2gray(data).reshape(-1, self.img_size, self.img_size, 1).astype('float32')\n","        data1/=255\n","        \n","        return data1\n","\n","    def call_pptocnn(self):\n","\n","        self.X_train = self.preprocesing_to_cnn(self.X_train)\n","        self.X_test = self.preprocesing_to_cnn(self.X_test)\n","\n","        self.num_pixels = self.X_train.shape[1] \n","\n","        self.y_train = to_categorical(self.y_train)\n","        self.y_test = to_categorical(self.y_test)\n","\n","        self.num_classes = self.y_train.shape[1]\n","\n","        self.input_shape = (self.img_size, self.img_size, 1) ##(self.img_size**2, ) ##(self.img_size, self.img_size, 1)\n","\n","        self.num_classes = self.y_train.shape[1]\n","        \n","        pass\n","\n","    def make_callbacks(self):\n","\n","        self.callbacks1 = [EarlyStopping(monitor = 'loss', patience = 6), ReduceLROnPlateau(monitor = 'loss', patience = 3), ModelCheckpoint('models/model.best1.hdf5',monitor='loss', save_best_only=True)]\n","        self.callbacks3 = [EarlyStopping(monitor = 'loss', patience = 6), ReduceLROnPlateau(monitor = 'loss', patience = 3), ModelCheckpoint('models/model.best3.hdf5', monitor='loss' , save_best_only=True)]\n","        self.callbacks2 = [ReduceLROnPlateau(monitor = 'loss', patience = 6), ReduceLROnPlateau(monitor = 'loss', patience = 3),  ModelCheckpoint('models/model.best2.hdf5', monitor='loss' , save_best_only=True)]\n","        self.callbacks4 = [EarlyStopping(monitor = 'loss', patience = 7), ReduceLROnPlateau(monitor = 'loss', patience = 4), ModelCheckpoint('models/model.best4.hdf5', monitor='loss' , save_best_only=True)]\n","        \n","        pass\n","\n","    def lung_condition(self, label): #pre-proc\n","        \n","        if label == 'NORMAL':\n","            return 0\n","        \n","        else:\n","            return 1\n","\n","    def set_preproc(self):\n","\n","        np.random.shuffle(self.train)\n","        np.random.shuffle(self.test)\n","        self.X_train, self.y_train = self.splitdata(self.train) #overwrites \n","        self.X_test, self.y_test = self.splitdata(self.test)\n","        \n","        pass\n","\n","    def preprocesing_to_mlp(self, data):\n","        \n","        data1 = color.rgb2gray(data).reshape(-1, self.img_size * self.img_size).astype('float32')\n","        \n","        data1 /= 255 # Data Normalization [0, 1]\n","        \n","        return data1\n","\n","    def mlp_tt(self): \n","\n","        self.X_train = self.preprocesing_to_mlp(self.X_train)\n","        self.X_test = self.preprocesing_to_mlp(self.X_test)\n","\n","        self.num_pixels = self.X_train.shape[1] \n","\n","        self.y_train = to_categorical(self.y_train)\n","        self.y_test = to_categorical(self.y_test)\n","\n","        self.num_classes = self.y_train.shape[1]\n","\n","        self.input_shape = (self.img_size, self.img_size, 1) ##(self.img_size**2, ) ##(self.img_size, self.img_size, 1)\n","\n","        self.num_classes = self.y_train.shape[1]\n","\n","        pass\n","\n","    def draw_learning_curve(self, history, type_model):\n","\n","        epochs_arr=[]\n","\n","        if type_model==\"mlp1\":\n","            epochs_arr=np.arange(0,self.max_epochs)\n","\n","        elif type_model==\"mlp2\":\n","            epochs_arr=np.arange(0,2*self.max_epochs)\n","\n","        fig = plt.figure(figsize = (16,12))\n","\n","        y_1=np.array(history.history[\"accuracy\"])\n","        y_2=np.array(history.history[\"val_accuracy\"])\n","\n","        plt.plot(epochs_arr, y_1, label=\"train\") \n","        plt.plot(epochs_arr, y_2, label=\"test\")\n","\n","        plt.xlabel(\"Epochs\")\n","        plt.ylabel(\"Accuracy Metric\")\n","\n","        plt.legend(loc='best')\n","        plt.grid(True)\n","\n","        plt.title(\"Accuracy (Train + Test vs. Epochs) {}\".format(type_model))\n","\n","        plt.savefig(\"/content/drive/MyDrive/ML_Datasets_Colab_Access/EE_456/results/\"+\"acc_{}.png\".format(type_model))\n","\n","        fig = plt.figure(figsize = (16,12))\n","\n","        y_1=np.array(history.history[\"loss\"])\n","        y_2=np.array(history.history[\"val_loss\"])\n","\n","        plt.plot(epochs_arr, y_1, label=\"train\") \n","        plt.plot(epochs_arr, y_2, label=\"test\")\n","\n","        plt.xlabel(\"Epochs\")\n","        plt.ylabel(\"Loss Metric\")\n","\n","        plt.legend(loc='best')\n","        plt.grid(True)\n","\n","        plt.title(\"Loss (Train + Test vs. Epochs) {}\".format(type_model))\n","\n","        plt.savefig(\"/content/drive/MyDrive/ML_Datasets_Colab_Access/EE_456/results/\"+\"loss_{}.png\".format(type_model))\n","\n","        pass\n","\n","    def get_mlp(self): #mlp layer, IO premade \n","            \n","        return Sequential([Dense(1024, input_dim = self.num_pixels, activation='relu'), Dense(self.num_classes, activation='softmax')])\n","\n","    def eval_model1(self, type_model):\n","\n","        #self.model = load_model('/content/drive/MyDrive/ML_Datasets_Colab_Access/EE_456/models/model.best1.hdf5')\n","\n","        x_train_now=self.X_train#.flatten() #np.reshape(self.X_train, self.input_shape).flatten()\n","        y_train_now=self.y_train#.flatten() #np.reshape(self.y_train, self.input_shape).flatten()\n","\n","        x_test_now=self.X_test#.flatten()\n","        y_test_now=self.y_test#.flatten()\n","\n","        learning_history = self.model.fit(x_train_now, y_train_now, batch_size = self.batch_size, epochs = self.max_epochs, verbose = 2, callbacks = self.callbacks1, validation_data=(x_test_now, y_test_now))\n","\n","        self.draw_learning_curve(learning_history, type_model)\n","\n","        self.y_pred=self.model.predict(x_test_now)\n","\n","        metric = tf.keras.metrics.TopKCategoricalAccuracy(k=1) \n","        metric.update_state(y_test_now, self.y_pred)\n","        acc=metric.result().numpy()\n","       \n","        print(\"Overall Precision Accuracy for model {}: {}\".format(type_model, acc))\n","\n","        metric_r=tf.keras.metrics.Recall()\n","        metric_r.update_state(y_test_now, self.y_pred)\n","\n","        acc_r=metric_r.result().numpy()\n","\n","        print(\"Overall Recall Accuracy for model {}: {}\".format(type_model, acc_r))\n","\n","        preds=np.argmax(self.y_pred, axis=-1) \n","        labels=np.argmax(y_test_now, axis=1)\n","\n","        print(classification_report(labels,preds, target_names=self.classes))\n","\n","        score = self.model.evaluate(x_test_now, y_test_now, verbose = 0)\n","        print('Test loss for model {}: {}%'.format(type_model, score[0] * 100))\n","        print('Test accuracy for model {}: {}%'.format(type_model, score[1] * 100))\n","\n","        print(\"MLP Error for model {}: {}\".format(type_model, 100 - score[1] * 100))\n","\n","        self.plot_confusion(type_model)\n","        self.random_validations(type_model)\n","\n","        pass\n","\n","    def plot_confusion(self, type_model):\n","\n","        preds=np.argmax(self.y_pred, axis=-1) \n","        labels=np.argmax(self.y_test, axis=-1)\n","\n","        df_cm = confusion_matrix(labels, preds)\n","\n","        t=df_cm[0][0]\n","        df_cm[0][0]=df_cm[0][1]\n","        df_cm[0][1]=t #swap for right conf matr\n","\n","        t=df_cm[1][1]\n","        df_cm[1][1]=df_cm[0][0]\n","        df_cm[0][0]=t #other swap for right class numbers \n","        \n","        plt.figure(figsize = (20,20))\n","\n","        sn.heatmap(df_cm, annot=True, cmap=\"icefire\", linewidths=1, cbar=False, xticklabels=self.classes, yticklabels=self.classes)\n","\n","        plt.xlabel(\"True\")\n","        plt.title(\"Confusion Matrix for Test and Validation: {}\".format(type_model))\n","        plt.ylabel(\"Predicted\")\n","\n","        plt.savefig(\"/content/drive/MyDrive/ML_Datasets_Colab_Access/EE_456/results/\"+\"cm_{}.png\".format(type_model), dpi=100)\n","\n","        pass\n","\n","    def random_validations(self, type_model):\n","        \n","        for i in range(self.num_rand_valids):\n","\n","            p_test = self.model.predict(self.X_test).argmax(axis=1)\n","                            \n","            j = np.random.randint(0, len(self.X_test))\n","\n","            plt.figure(figsize = (12,12))\n","\n","            img_j=np.reshape(self.X_test[j], (self.img_size, self.img_size))\n","\n","            plt.imshow(img_j, cmap='gray')\n","            yv=np.where(self.y_test[j]==1)[0][0]\n","\n","            pvc=np.max(self.y_pred[j])\n","\n","            plt.title(\"True label: {}, Predicted: {} with confidence: {} : {}\".format(self.classes[yv], self.classes[p_test[j]], pvc, type_model))\n","\n","            plt.savefig(\"/content/drive/MyDrive/ML_Datasets_Colab_Access/EE_456/results/pic_{}_{}.png\".format(i, type_model))\n","\n","        pass #not plotted precision and recall per epich, as irrelevant to metric study \n","\n","    def pre_m(self): #model 1\n","\n","        self.model=self.get_mlp()\n","        self.model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n","        print(self.model.summary())\n","\n","        pass\n","\n","    def get_mlpv2(self):#model 2\n","            \n","        return Sequential([Dense(1024, input_dim=self.num_pixels, activation='relu'), Dropout(0.4), Dense(512, activation='relu'), Dropout(0.3), Dense(128, activation='relu'), Dropout(0.3), Dense(self.num_classes, activation='softmax')])\n","\n","    def pre_m2(self):\n","\n","        self.model = self.get_mlpv2()\n","        self.model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n","        print(self.model.summary())\n","\n","        pass\n","\n","    def eval_model2(self, type_model):\n","\n","        #self.model = load_model('/content/drive/MyDrive/ML_Datasets_Colab_Access/EE_456/models/model.best2.hdf5')\n","\n","        x_train_now=self.X_train#.flatten() #np.reshape(self.X_train, self.input_shape).flatten()\n","        y_train_now=self.y_train#.flatten() #np.reshape(self.y_train, self.input_shape).flatten()\n","\n","        x_test_now=self.X_test#.flatten()\n","        y_test_now=self.y_test#.flatten()\n","\n","        learning_history = self.model.fit(x_train_now, y_train_now, batch_size = self.batch_size, epochs = self.max_epochs*2, verbose = 2, callbacks = self.callbacks2, validation_data=(x_test_now, y_test_now))\n","\n","        score = self.model.evaluate(self.X_test, self.y_test, verbose = 0)\n","        print('Test loss for model {}: {}%'.format(type_model, score[0] * 100))\n","        print('Test accuracy for model {}: {}%'.format(type_model, score[1] * 100))\n","\n","        print(\"MLP Error for model {}: {}\".format(type_model, 100 - score[1] * 100))\n","\n","        self.draw_learning_curve(learning_history, type_model)\n","\n","        self.y_pred=self.model.predict(x_test_now)\n","\n","        metric = tf.keras.metrics.TopKCategoricalAccuracy(k=1) \n","        metric.update_state(y_test_now, self.y_pred)\n","        acc=metric.result().numpy()\n","       \n","        print(\"Overall Precision Accuracy for model {}: {}\".format(type_model, acc))\n","\n","        metric_r=tf.keras.metrics.Recall()\n","        metric_r.update_state(y_test_now, self.y_pred)\n","\n","        acc_r=metric_r.result().numpy()\n","\n","        print(\"Overall Recall Accuracy for model {}: {}\".format(type_model, acc_r))\n","\n","        preds=np.argmax(self.y_pred, axis=-1) \n","        labels=np.argmax(y_test_now, axis=1)\n","\n","        print(classification_report(labels,preds, target_names=self.classes))\n","\n","        self.plot_confusion(type_model)\n","        self.random_validations(type_model)\n","\n","        pass\n","\n","    def data_aug(self): #data aug\n","\n","        datagen = ImageDataGenerator(featurewise_center = False, samplewise_center = False, featurewise_std_normalization = False, samplewise_std_normalization = False, zca_whitening = False, horizontal_flip = False, vertical_flip = False, rotation_range = 10, zoom_range = 0.1, width_shift_range = 0.1, height_shift_range = 0.1)\n","\n","        datagen.fit(self.X_train)\n","        self.train_gen = datagen.flow(self.X_train, self.y_train, batch_size = 32)\n","\n","        pass\n","\n","    def get_modelcnn(self): #CNN model\n","\n","        return Sequential([Conv2D(16, kernel_size=(3, 3), activation='relu', padding='same', input_shape = self.input_shape), Conv2D(16, kernel_size=(3, 3), activation='relu', padding='same'), BatchNormalization(), MaxPool2D(pool_size=(2, 2)), Dropout(0.25), Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'), Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'), BatchNormalization(), MaxPool2D(pool_size=(2, 2)), Dropout(0.25), Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'), Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'), BatchNormalization(), MaxPool2D(pool_size=(2, 2)), Dropout(0.25), Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same' ), Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'), BatchNormalization(), MaxPool2D(pool_size=(2, 2)), Dropout(0.25), Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same' ), Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'), BatchNormalization(), MaxPool2D(pool_size=(2, 2)), Dropout(0.25), Flatten(), Dense(512, activation='relu'), Dropout(0.5), Dense(256, activation='relu'), Dropout(0.5), Dense(64, activation='relu'), Dropout(0.5), Dense(self.num_classes, activation = \"softmax\")])\n","\n","    def eval_cnn_m1(self, type_model): #fit and eval cnn 1\n","\n","        self.model = self.get_modelcnn()\n","        self.model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n","\n","        x_train_now=self.X_train#.flatten() #np.reshape(self.X_train, self.input_shape).flatten()\n","        y_train_now=self.y_train#.flatten() #np.reshape(self.y_train, self.input_shape).flatten()\n","\n","        x_test_now=self.X_test#.flatten()\n","        y_test_now=self.y_test#.flatten()\n","\n","        learning_history = model.fit(x_train_now, y_train_now, batch_size = 64, epochs = 100, verbose = 1, callbacks = self.callbacks3, validation_data = (x_test_now, y_test_now))\n","\n","        #self.model = load_model('/content/drive/MyDrive/ML_Datasets_Colab_Access/EE_456/models/model.best3.hdf5')\n","\n","        score = self.model.evaluate(self.X_test, self.y_test, verbose = 0)\n","        print('Test loss: {}%'.format(score[0] * 100))\n","        print('Test accuracy: {}%'.format(score[1] * 100))\n","\n","        print(\"MLP Error: %.2f%%\" % (100 - score[1] * 100))\n","\n","        self.draw_learning_curve(learning_history, type_model)\n","\n","        pass\n","\n","    def get_modelcnn_v2(self): #cnn model 2:\n","\n","        return Sequential([Conv2D(16, kernel_size=(3, 3), activation='relu', padding='same', input_shape = self.input_shape), Conv2D(16, kernel_size=(3, 3), activation='relu', padding='same'), BatchNormalization(), MaxPool2D(pool_size=(2, 2)), Dropout(0.2), Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'), Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'), BatchNormalization(), MaxPool2D(pool_size=(2, 2)),Dropout(0.2), Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'), Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'), BatchNormalization(), MaxPool2D(pool_size=(2, 2)), Dropout(0.2), Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'),Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'), BatchNormalization(), MaxPool2D(pool_size=(2, 2)), Dropout(0.2), Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'), Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'), BatchNormalization(), MaxPool2D(pool_size=(2, 2)), Dropout(0.2), Flatten(), Dense(1024, activation='relu'), BatchNormalization(), Dropout(0.5), Dense(512, activation='relu'), BatchNormalization(), Dropout(0.4), Dense(256, activation='relu'), BatchNormalization(), Dropout(0.3), Dense(64, activation='relu'), BatchNormalization(), Dropout(0.2), Dense(self.num_classes, activation = \"softmax\")])\n","\n","    def eval_cnn_model2(self, type_model):\n","\n","        self.model = self.get_modelcnn_v2()\n","        self.model.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n","        self.model.summary()\n","\n","        learning_history = self.model.fit_generator((self.train_gen), epochs = 100, steps_per_epoch = self.X_train.shape[0] // 32, validation_data = (self.X_test, self.y_test), callbacks = self.callbacks4)\n","\n","        #self.model = load_model('/content/drive/MyDrive/ML_Datasets_Colab_Access/EE_456/models/model.best4.hdf5')\n","\n","        score = self.model.evaluate(self.X_test, self.y_test, verbose = 0)\n","        print('Test loss: {}%'.format(score[0] * 100))\n","        print('Test accuracy: {}%'.format(score[1] * 100))\n","\n","        print(\"MLP Error: %.2f%%\" % (100 - score[1] * 100))\n","\n","        self.draw_learning_curve(learning_history, type_model)\n","\n","        y_pred = self.model.predict(self.X_test) #pred 2\n","        self.y_pred = np.argmax(y_pred, axis = 1)\n","\n","        self.y_pre_test = np.argmax(self.y_test, axis = 1)\n","\n","        pass\n","\n","    def show_condition(self, num):\n","        \n","        if num == 0:\n","            return 'NORMAL'\n","        \n","        return 'PNEUMONIA'\n","\n","    def final_classification(self, type_model):\n","\n","        cnt_error = []\n","        for idx, (a, b) in enumerate(zip(self.y_pre_test, self.y_pred)):\n","            if a == b: \n","                continue\n","            cnt_error.append(a)# test\n","\n","        cnt_error = np.unique(cnt_error, return_counts = True)\n","        sns.set_style(\"darkgrid\")\n","        plt.figure(figsize = (15, 7))\n","        sns.barplot([self.show_condition(x) for x in cnt_error[0]], cnt_error[1], palette=\"muted\")\n","        \n","        plt.savefig(\"results/final_class_{}.png\".format(type_model))\n","\n","        cnt_ind = 1\n","        list_idx = []\n","        fig = plt.figure(figsize=(14, 14))\n","        X_test_plot = self.X_test.reshape(-1, self.img_size, self.img_size)\n","        \n","        for idx, (a, b) in enumerate(zip(self.y_pre_test, self.y_pred)):\n","            \n","            if(cnt_ind > 16):\n","                break\n","            \n","            if a == b: \n","                continue\n","            \n","            plt.subplot(4, 4, cnt_ind)\n","            plt.imshow(X_test_plot[idx], cmap='gray', interpolation='none')\n","            plt.title('y_true = {0}\\ny_pred = {1}\\n ind = {2}'.format(self.show_condition(a), self.show_condition(b), idx))\n","            plt.tight_layout()\n","            list_idx.append(idx)\n","            cnt_ind += 1\n","\n","            \n","\n","        print(classification_report(self.y_pre_test, self.y_pred)) #report class\n","\n","        pass\n","\n","    def run_sequence_model1(self): #model 1 normal mlp\n","\n","        type_model=\"mlp1\"\n","        \n","        print(\"\\nRunning MLP Model #1 ... \\n\")\n","\n","        self.set_train()\n","        self.explore_plot(type_model)\n","        self.show_example_image(type_model)\n","        self.set_preproc()\n","        self.mlp_tt()\n","        \n","        self.make_callbacks()\n","        self.pre_m()\n","        self.eval_model1(type_model)\n","        \n","        print(\"\\nMLP Model 1 Generated. \\n\")\n","\n","        pass\n","\n","    def run_sequence_model2(self): #model 2 normal mlp\n","\n","        type_model=\"mlp2\"\n","        \n","        print(\"\\nRunning MLP Model #2 ... \\n\")\n","    \n","        self.set_train()\n","        self.explore_plot(type_model)\n","        self.show_example_image(type_model)\n","        self.set_preproc()\n","        self.mlp_tt()\n","        \n","        self.make_callbacks()\n","        self.pre_m2()\n","        self.eval_model2(type_model)\n","        \n","        print(\"\\nMLP Model 2 Generated. \\n\")\n","\n","        pass\n","\n","    def run_sequence_model3(self): #cnn layers v1\n","\n","        type_model=\"cnn1\"\n","        \n","        print(\"\\nRunning CNN Model #1 ... \\n\")\n","\n","        self.set_preproc()\n","        self.call_pptocnn()\n","\n","        self.make_callbacks()\n","        self.get_modelcnn()\n","        self.eval_cnn_m1(type_model)\n","        \n","        print(\"\\nCNN Model 1 Generated. \\n\")\n","\n","        pass\n","\n","    def run_sequence_model4(self): #cnn model v2\n","\n","        type_model=\"cnn2\"\n","        \n","        print(\"\\nRunning CNN Model #2 ... \\n\")\n","    \n","        self.data_aug()\n","        self.make_callbacks()\n","\n","        self.get_modelcnn_v2()\n","        self.eval_cnn_model2(type_model)\n","        self.final_classification()\n","        \n","        print(\"\\nCNN Model 2 Generated. \\n\")\n","        \n","        pass"],"metadata":{"id":"LxnVwEIrLNL5","executionInfo":{"status":"ok","timestamp":1668906007715,"user_tz":300,"elapsed":166,"user":{"displayName":"Arya Keni","userId":"06459928781733841639"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["Code Runner"],"metadata":{"id":"ZFCJa4SDLbiH"}},{"cell_type":"code","source":["#start\n","\n","if __name__==\"__main__\":\n","\n","    cfp=CNN_FP()\n","    cfp.run_sequence_model1()\n","    cfp.run_sequence_model2()\n","    #cfp.run_sequence_model3() #only the 2 main mlp's for now \n","    #cfp.run_sequence_model4()\n","\n","#end"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1lMcfGtMsYEqh4rL7xA1gH4X0Oxe8c87k"},"id":"ycTxpkOsLQxC","executionInfo":{"status":"ok","timestamp":1668906580417,"user_tz":300,"elapsed":560882,"user":{"displayName":"Arya Keni","userId":"06459928781733841639"}},"outputId":"20b35291-1c80-4704-bb88-055e0e985340"},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}